#!/usr/bin/env node

/**
 * Demo: Multi-Iteration Beam Search with N=4, M=2
 *
 * âœ¨ Latest Features & Innovations:
 * - Real-time rate limiting metrics API (see /demo or http://localhost:3000/demo)
 * - Accurate token tracking across all providers (LLM, Vision, Critique, Image)
 * - Improved Vision API error handling with detailed diagnostics
 * - Global rate limiter initialization for consistent metrics
 *
 * This demonstrates the complete beam search algorithm:
 * - N = 4 (beam width: 4 candidates per iteration)
 * - M = 2 (keep top: 2 best candidates survive each round)
 * - Expansion ratio: N/M = 2 children per parent
 *
 * Algorithm Flow:
 * 1. Iteration 0: Generate 4 diverse WHAT+HOW pairs (expansion)
 *    â†’ Rank by score â†’ Keep top 2
 * 2. Iteration 1: 2 parents generate 4 children (refine WHAT/content)
 *    â†’ Rank by score â†’ Keep top 2
 * 3. Iteration 2: 2 parents generate 4 children (refine HOW/style)
 *    â†’ Rank by score â†’ Keep top 2
 * 4. Return best candidate from final iteration
 *
 * Rate Limiting (Prevents OpenAI 429 Errors):
 * - Uses sensible defaults (LLM: 3, ImageGen: 2, Vision: 3 concurrent)
 * - Configurable via environment variables:
 *   - BEAM_SEARCH_RATE_LIMIT_LLM (default: 3 concurrent)
 *   - BEAM_SEARCH_RATE_LIMIT_IMAGE_GEN (default: 2 concurrent)
 *   - BEAM_SEARCH_RATE_LIMIT_VISION (default: 3 concurrent)
 * - Monitor live metrics at: http://localhost:3000/api/demo/rate-limits/status
 * - Demo visualization: http://localhost:3000/demo
 *
 * Token Tracking (NEW - Fixed in this session):
 * - Accurately tracks tokens for all provider types:
 *   â€¢ LLM (GPT-4): Expansion, refinement, critique operations
 *   â€¢ Vision (GPT-4V): Image analysis and ranking
 *   â€¢ Critique: Ranking-based, LLM-based, and rule-based paths
 *   â€¢ Image Generation: DALL-E operations (counted separately)
 * - Standardized metadata field names (tokensUsed) across all paths
 * - Cost tracking shows real token attribution by provider
 *
 * Vision API Error Handling (IMPROVED in this session):
 * - Three-level response validation (structure, content, trimmed)
 * - Detailed error diagnostics include:
 *   â€¢ Model name (helps identify which model failed)
 *   â€¢ Finish reason (explains why: length, content_filter, stop, etc.)
 *   â€¢ Refusal status (indicates content policy violations)
 *   â€¢ Original content length (shows if response was truncated)
 * - Prevents null/undefined access errors
 * - Consistent with openai-llm-provider.js best practices
 *
 * Output Structure:
 * - Metadata and images saved to: output/YYYY-MM-DD/ses-HHMMSS/
 * - Uses OutputPathManager for consistent path construction
 * - Complete token usage and cost analysis included in metadata
 *
 * Usage:
 *   node demo-beam-search.js
 *
 * Requirements:
 *   - OPENAI_API_KEY environment variable set
 *   - Optional: npm start (in another terminal) to run API server for demo metrics
 */

require('dotenv').config();

const { beamSearch } = require('./src/orchestrator/beam-search.js');
const rateLimitConfig = require('./src/config/rate-limits.js');
const OpenAILLMProvider = require('./src/providers/openai-llm-provider.js');
const OpenAIImageProvider = require('./src/providers/openai-image-provider.js');
const OpenAIVisionProvider = require('./src/providers/openai-vision-provider.js');
const CritiqueGenerator = require('./src/services/critique-generator.js');
const ImageRanker = require('./src/services/image-ranker.js');
const MetadataTracker = require('./src/services/metadata-tracker.js');
const TokenTracker = require('./src/utils/token-tracker.js');
const DebugLogger = require('./src/utils/debug-logger.js');
const { MODEL_PRICING } = require('./src/config/model-pricing.js');
const { buildSessionPath, buildMetadataPath, DEFAULT_OUTPUT_DIR } = require('./src/utils/output-path-manager.js');

/**
 * Custom logging wrapper to track beam search progress with debug info
 */
class BeamSearchLogger {
  constructor(providers, options = {}) {
    this.originalProviders = providers;
    this.iterationCounts = { llm: 0, imageGen: 0, vision: 0, critique: 0 };
    this.currentIteration = -1;
    this.debugLogger = new DebugLogger({ debug: options.debug !== false }); // Debug enabled by default
  }

  wrapProviders() {
    const wrapped = {
      llm: this.wrapLLM(this.originalProviders.llm),
      imageGen: this.wrapImageGen(this.originalProviders.imageGen),
      vision: this.wrapVision(this.originalProviders.vision),
      critiqueGen: this.wrapCritique(this.originalProviders.critiqueGen)
    };
    // Add imageRanker if provided
    if (this.originalProviders.imageRanker) {
      wrapped.imageRanker = this.wrapImageRanker(this.originalProviders.imageRanker);
    }
    return wrapped;
  }

  wrapImageRanker(imageRanker) {
    // Track comparison stats for this ranking session
    let comparisonStats = { apiCalls: 0, transitivityInferred: 0, totalVotes: 0 };

    // Helper to format candidate ID for display
    const formatId = (img) => {
      // Global ID format: "i{iteration}c{candidateId}" e.g., "i0c1"
      if (typeof img.candidateId === 'string' && img.candidateId.startsWith('i')) {
        return img.candidateId; // Already formatted
      }
      // Fallback for simple numeric IDs
      return `c${img.candidateId}`;
    };

    // Wrap compareWithEnsemble to log individual comparisons
    const originalCompareWithEnsemble = imageRanker.compareWithEnsemble.bind(imageRanker);
    imageRanker.compareWithEnsemble = async (imgA, imgB, prompt, options) => {
      const ensembleSize = options.ensembleSize || imageRanker.defaultEnsembleSize || 1;
      comparisonStats.apiCalls++;
      comparisonStats.totalVotes += ensembleSize;

      const idA = formatId(imgA);
      const idB = formatId(imgB);
      console.log(`        ğŸ”„ Comparing: ${idA} vs ${idB} (${ensembleSize} vote${ensembleSize > 1 ? 's' : ''})...`);

      const result = await originalCompareWithEnsemble(imgA, imgB, prompt, options);

      // Log multi-factor ranks (1=better, 2=worse)
      const ranksA = result.aggregatedRanks?.A || {};
      const ranksB = result.aggregatedRanks?.B || {};
      console.log(`           â€¢ Ranks [${idA}]: align=${ranksA.alignment?.toFixed(2) || '?'} aesth=${ranksA.aesthetics?.toFixed(2) || '?'} combined=${ranksA.combined?.toFixed(2) || '?'}`);
      console.log(`           â€¢ Ranks [${idB}]: align=${ranksB.alignment?.toFixed(2) || '?'} aesth=${ranksB.aesthetics?.toFixed(2) || '?'} combined=${ranksB.combined?.toFixed(2) || '?'}`);

      // Log ensemble votes if applicable
      if (ensembleSize > 1) {
        console.log(`           â€¢ Votes: A=${result.votes.A}, B=${result.votes.B} â†’ Winner: ${result.winner} (conf: ${(result.confidence * 100).toFixed(0)}%)`);
      } else {
        console.log(`           â€¢ Winner: ${result.winner} (lower combined rank wins)`);
      }

      return result;
    };

    // Wrap _findBestWithTransitivity to log transitivity inferences
    const originalFindBest = imageRanker._findBestWithTransitivity.bind(imageRanker);
    imageRanker._findBestWithTransitivity = async (candidates, prompt, graph, options) => {
      // Wrap canInferWinner to track transitivity usage
      const originalCanInfer = graph.canInferWinner.bind(graph);
      graph.canInferWinner = (idA, idB) => {
        const result = originalCanInfer(idA, idB);
        if (result) {
          comparisonStats.transitivityInferred++;
          const loserId = result.winner === idA ? idB : idA;
          console.log(`        âš¡ Transitivity: ${result.winner} > ${loserId} (skipped API call!)`);
        }
        return result;
      };

      return originalFindBest(candidates, prompt, graph, options);
    };

    return {
      rankImages: async (images, prompt, options) => {
        // Reset stats for each ranking call
        comparisonStats = { apiCalls: 0, transitivityInferred: 0, totalVotes: 0 };

        const ensembleSize = options.ensembleSize || imageRanker.defaultEnsembleSize || 1;
        const method = ensembleSize > 1 ? `ensemble(${ensembleSize} votes/pair)` : 'single-vote';
        console.log(`\n  ğŸ… Pairwise ranking: ${images.length} candidates, keepTop=${options.keepTop || images.length}, ${method}`);
        console.log('     â€¢ ID format: i{iter}c{candidate} (e.g., i0c1 = iteration 0, candidate 1)');
        console.log('     â€¢ Using transitive inference to minimize comparisons');
        console.log('     â€¢ Multi-factor scoring: alignment (70%) + aesthetics (30%)');

        try {
          const rankResult = await imageRanker.rankImages(images, prompt, options);

          // Handle new return format: { rankings, metadata }
          const rankings = Array.isArray(rankResult) ? rankResult : rankResult.rankings;

          // Summary stats
          console.log('\n     ğŸ“Š Comparison stats:');
          console.log(`        â€¢ API comparisons: ${comparisonStats.apiCalls}`);
          console.log(`        â€¢ Total votes cast: ${comparisonStats.totalVotes}`);
          console.log(`        â€¢ Transitivity inferences: ${comparisonStats.transitivityInferred}`);
          if (comparisonStats.transitivityInferred > 0) {
            console.log(`        â€¢ API calls saved: ${comparisonStats.transitivityInferred} (via transitivity)`);
          }

          console.log(`\n     âœ… Ranking complete: ${rankings.length} candidates ranked`);
          rankings.forEach((r, i) => {
            const reason = r.reason || 'No reason provided';
            const truncatedReason = reason.length > 60 ? reason.substring(0, 60) + '...' : reason;
            const ranks = r.ranks
              ? ` [align=${r.ranks.alignment?.toFixed(2)}, aesth=${r.ranks.aesthetics?.toFixed(2)}, comb=${r.ranks.combined?.toFixed(2)}]`
              : '';
            console.log(`        ${i + 1}. Candidate ${r.candidateId}${ranks}: "${truncatedReason}"`);
          });
          return rankings;
        } catch (error) {
          console.error(`     âŒ Ranking failed: ${error.message}`);
          throw error;
        }
      }
    };
  }

  wrapLLM(llm) {
    return {
      refinePrompt: async (prompt, options) => {
        if (options.operation === 'expand' && this.currentIteration !== 0) {
          this.currentIteration = 0;
          console.log('\n' + '='.repeat(80));
          console.log('ğŸ”„ ITERATION 0: Initial Expansion (N=4 diverse candidates)');
          console.log('='.repeat(80));
        }
        const result = await llm.refinePrompt(prompt, options);

        // Display debug info (model + tokens)
        if (result.metadata) {
          const debugInfo = this.debugLogger.logProviderCall({
            provider: 'llm',
            operation: options.operation || 'refine',
            metadata: result.metadata
          });
          if (debugInfo) {
            console.log(debugInfo);
          }
        }

        return result;
      },
      combinePrompts: async (what, how) => {
        const result = await llm.combinePrompts(what, how);

        // Display debug info for combine operation
        if (result.metadata) {
          const debugInfo = this.debugLogger.logProviderCall({
            provider: 'llm',
            operation: 'combine',
            metadata: result.metadata
          });
          if (debugInfo) {
            console.log(debugInfo);
          }
        }

        return result;
      }
    };
  }

  wrapImageGen(imageGen) {
    return {
      generateImage: async (prompt, options) => {
        if (options.iteration !== this.currentIteration && options.iteration > 0) {
          this.currentIteration = options.iteration;
          const dimension = options.iteration % 2 === 1 ? 'WHAT (content)' : 'HOW (style)';
          console.log('\n' + '='.repeat(80));
          console.log(`ğŸ”„ ITERATION ${options.iteration}: Refinement - ${dimension}`);
          console.log('='.repeat(80));
        }

        console.log(`  ğŸ–¼ï¸  Generating image for candidate ${options.candidateId}...`);
        const result = await imageGen.generateImage(prompt, options);

        // Display debug info (model, no tokens for DALL-E)
        if (result.metadata) {
          const debugInfo = this.debugLogger.logProviderCall({
            provider: 'image',
            operation: 'generate',
            metadata: result.metadata
          });
          if (debugInfo) {
            console.log(debugInfo);
          }
        }

        if (result.localPath) {
          console.log(`     ğŸ’¾ Saved: ${result.localPath}`);
        }
        return result;
      }
    };
  }

  wrapVision(vision) {
    return {
      analyzeImage: async (imageUrl, prompt) => {
        const result = await vision.analyzeImage(imageUrl, prompt);

        // Display debug info (model + tokens)
        if (result.metadata) {
          const debugInfo = this.debugLogger.logProviderCall({
            provider: 'vision',
            operation: 'analyze',
            metadata: result.metadata
          });
          if (debugInfo) {
            console.log(debugInfo);
          }
        }

        console.log(`     ğŸ“Š Scores: alignment=${result.alignmentScore}/100, aesthetic=${result.aestheticScore}/10`);
        return result;
      }
    };
  }

  wrapCritique(critique) {
    const self = this;
    return {
      generateCritique: async (evaluation, prompts, userPrompt, options) => {
        const result = await critique.generateCritique(evaluation, prompts, userPrompt, options);

        // Display debug info for critique generation
        if (result.metadata) {
          const debugInfo = self.debugLogger.logProviderCall({
            provider: 'critique',
            operation: 'generate',
            metadata: result.metadata
          });
          if (debugInfo) {
            console.log(debugInfo);
          }
        }

        // Display the actual critique content for top candidates
        console.log(`\n  ğŸ“ Critique for refinement (${options.dimension?.toUpperCase() || 'unknown'} dimension):`);

        // Show key critique components (result has critique, recommendation, reason as strings)
        if (result.critique) {
          const truncatedCritique = result.critique.length > 120
            ? result.critique.substring(0, 120) + '...'
            : result.critique;
          console.log(`     âœ— Issue: ${truncatedCritique}`);
        }

        if (result.recommendation) {
          const truncatedRec = result.recommendation.length > 120
            ? result.recommendation.substring(0, 120) + '...'
            : result.recommendation;
          console.log(`     â†’ Recommendation: ${truncatedRec}`);
        }

        if (result.reason) {
          const truncatedReason = result.reason.length > 100
            ? result.reason.substring(0, 100) + '...'
            : result.reason;
          console.log(`     ğŸ’¡ Reason: ${truncatedReason}`);
        }

        return result;
      }
    };
  }
}

async function demo() {
  // Ensemble configuration - use 3 for reliable ranking, 1 for speed
  const ensembleSize = parseInt(process.env.ENSEMBLE_SIZE || '3', 10);

  console.log('ğŸš€ Beam Search Demo: Multi-Iteration Refinement');
  console.log('='.repeat(80));
  console.log('Configuration:');
  console.log('  â€¢ N = 4 (beam width: 4 candidates per iteration)');
  console.log('  â€¢ M = 2 (keep top: 2 best candidates survive)');
  console.log('  â€¢ Expansion ratio: 2 children per parent');
  console.log('  â€¢ Max iterations: 3 (iteration 0, 1, 2)');
  console.log(`  â€¢ Ensemble size: ${ensembleSize} (votes per comparison for reliability)`);
  console.log('  â€¢ Vision model: gpt-5-nano with Flex pricing ($0.025/1M tokens - 50% savings!)');
  console.log('');
  console.log('âœ¨ Latest Innovations (just added):');
  console.log('  â€¢ Real-time rate limiting visualization API');
  console.log('  â€¢ Fixed token tracking bug (Vision & Critique now properly tracked)');
  console.log('  â€¢ Improved Vision API error diagnostics');
  console.log('  â€¢ Global rate limiter initialization for consistent metrics');
  console.log('');
  console.log('Streamlined Flow (unified pairwise ranking):');
  console.log('  1. Generate images (no per-image vision scoring)');
  console.log('  2. Ensemble pairwise ranking â†’ multiple votes per pair for reliability');
  console.log('  3. Transitive inference â†’ minimizes API calls (if A>B and B>C, skip A vs C)');
  console.log('  4. Critique uses ranking feedback â†’ refines prompts');
  console.log('');
  console.log('Rate Limiting (prevents OpenAI 429 errors):');
  console.log(`  â€¢ LLM concurrency: ${rateLimitConfig.defaults.llm} requests`);
  console.log(`  â€¢ Image Gen concurrency: ${rateLimitConfig.defaults.imageGen} requests`);
  console.log(`  â€¢ Vision concurrency: ${rateLimitConfig.defaults.vision} requests`);
  console.log('  â€¢ Configure via: BEAM_SEARCH_RATE_LIMIT_* env vars');
  console.log('  â€¢ Ensemble size via: ENSEMBLE_SIZE env var (default: 3)');
  console.log('  â€¢ ğŸ“Š Monitor live metrics: http://localhost:3000/api/demo/rate-limits/status');
  console.log('');
  console.log('ğŸ’° Token Tracking (FIXED - Accurate provider attribution):');
  console.log('  â€¢ LLM: GPT-4 expansion, refinement, critique operations');
  console.log('  â€¢ Vision: GPT-4V image analysis and ranking comparisons');
  console.log('  â€¢ Critique: Ranking-based, LLM-based, and rule-based evaluation');
  console.log('  â€¢ Image Gen: DALL-E 3 generation (separate counter)');
  console.log('  â€¢ See token report at end for full cost breakdown');
  console.log('');
  console.log('ğŸ’¡ Cost Optimization with Flex Pricing:');
  console.log('  â€¢ Vision model uses OpenAI Flex tier pricing');
  console.log('  â€¢ 50% cost savings vs Standard pricing tier');
  console.log('  â€¢ Trade-off: Occasional 429 rate limits, handled with automatic retry');
  console.log('  â€¢ See docs/FLEX_PRICING_STRATEGY.md for complete strategy details');
  console.log('='.repeat(80));

  // Check for API key
  if (!process.env.OPENAI_API_KEY) {
    console.error('\nâŒ Error: OPENAI_API_KEY not found in environment');
    console.error('   Please set it in your .env file or environment');
    process.exit(1);
  }

  // Generate session ID in ses-HHMMSS format
  const now = new Date();
  const hours = String(now.getHours()).padStart(2, '0');
  const minutes = String(now.getMinutes()).padStart(2, '0');
  const seconds = String(now.getSeconds()).padStart(2, '0');
  const sessionId = `ses-${hours}${minutes}${seconds}`;

  // Configuration
  const userPrompt = 'an almost photoreal painting that feels a little bit like Bierstadt of a grandiose american landscape. there is a small and subtle but aluring female figure in the middle ground.';

  // Initialize providers
  console.log('\nğŸ”§ Initializing providers...');
  const providerConfig = require('./src/config/provider-config.js');
  const providers = {
    llm: new OpenAILLMProvider(process.env.OPENAI_API_KEY),
    imageGen: new OpenAIImageProvider(process.env.OPENAI_API_KEY, { sessionId }),
    vision: new OpenAIVisionProvider(process.env.OPENAI_API_KEY, {
      model: process.env.OPENAI_VISION_MODEL || providerConfig.vision.model
    }),
    critiqueGen: new CritiqueGenerator({ apiKey: process.env.OPENAI_API_KEY }),
    imageRanker: new ImageRanker({
      apiKey: process.env.OPENAI_API_KEY,
      defaultEnsembleSize: ensembleSize
    })
  };
  console.log(`âœ… All providers initialized (ImageRanker with ensembleSize=${ensembleSize})`);

  // Wrap providers with logging (includes imageRanker)
  const logger = new BeamSearchLogger(providers);
  const wrappedProviders = logger.wrapProviders();

  // Initialize metadata tracker
  console.log(`ğŸ“Š Initializing metadata tracker (session: ${sessionId})...`);
  const metadataTracker = new MetadataTracker({
    sessionId,
    userPrompt,
    config: {
      beamWidth: 4,
      keepTop: 2,
      maxIterations: 3,
      alpha: 0.7,
      temperature: 0.8
    }
  });
  await metadataTracker.initialize();
  console.log('âœ… Metadata tracker ready');

  // Initialize token tracker for cost efficiency
  console.log(`ğŸ’° Initializing token efficiency tracker (session: ${sessionId})...`);
  const tokenTracker = new TokenTracker({
    sessionId,
    pricing: MODEL_PRICING
  });
  console.log('âœ… Token tracker ready - cost tracking enabled');

  const config = {
    beamWidth: 4,        // N = 4 candidates
    keepTop: 2,          // M = 2 survivors
    maxIterations: 3,    // Run 3 iterations (0, 1, 2)
    alpha: 0.7,          // 70% alignment, 30% aesthetic
    temperature: 0.8,    // Stochastic variation for diversity
    ensembleSize: ensembleSize,  // Ensemble votes for ranking decisions
    metadataTracker,     // Add metadata tracker to config
    tokenTracker         // Add token tracker to config
    // Note: Rate limits use defaults from rate-limits.js automatically
    // No need to specify rateLimitConcurrency - beam search uses sensible defaults
    // Can override via BEAM_SEARCH_RATE_LIMIT_* environment variables
  };

  console.log('\nğŸ“ User Prompt: "' + userPrompt + '"');
  console.log('\nâ±ï¸  Starting beam search...\n');

  // Track progress for real-time feedback
  let candidateCount = 0;
  let iterationCount = 0;

  // Callback for individual candidate processing
  config.onCandidateProcessed = (candidate) => {
    candidateCount++;
    const globalId = `i${candidate.metadata.iteration}c${candidate.metadata.candidateId}`;
    const hasImage = candidate.image?.url ? 'âœ“' : 'âœ—';
    const score = candidate.totalScore ? ` (score: ${candidate.totalScore.toFixed(2)})` : '';
    console.log(`  ğŸ“¦ Candidate ${globalId} processed${score} [${hasImage} image]`);
  };

  // Callback for iteration completion
  config.onIterationComplete = (data) => {
    iterationCount++;
    const { iteration, candidates, topCandidates } = data;
    console.log(`\nğŸ“Š Iteration ${iteration} complete:`);
    console.log(`   Generated: ${candidates?.length || 0} candidates`);
    console.log(`   Advanced: ${topCandidates?.length || 0} to next iteration`);

    // Show top candidates from this iteration
    if (topCandidates && topCandidates.length > 0) {
      console.log(`   ğŸ† Top performers:`);
      topCandidates.slice(0, 2).forEach((cand, idx) => {
        const globalId = `i${cand.metadata.iteration}c${cand.metadata.candidateId}`;
        const score = cand.totalScore ? cand.totalScore.toFixed(2) : '?';
        console.log(`      ${idx + 1}. ${globalId} (score: ${score})`);
      });
    }
    console.log();
  };

  const startTime = Date.now();

  // Run beam search with callbacks
  const winner = await beamSearch(userPrompt, wrappedProviders, config);

  const endTime = Date.now();
  const duration = ((endTime - startTime) / 1000).toFixed(1);

  // Display results
  console.log('\n' + '='.repeat(80));
  console.log('ğŸ† FINAL COMPARISON: Top 2 Candidates');
  console.log('='.repeat(80));

  // Display both finalists side by side
  const finalists = winner.finalists || [winner];

  // Helper to show text with expansion indicator
  const showText = (label, text, maxLength = 80) => {
    if (!text) return;
    if (text.length <= maxLength) {
      console.log(`   ${label}: "${text}"`);
    } else {
      const abbrev = text.substring(0, maxLength);
      const remaining = text.length - maxLength;
      console.log(`   ${label}: "${abbrev}"`);
      console.log(`   ${' '.repeat(label.length + 2)} [+${remaining} more characters]`);
    }
  };

  // Helper to show comparative ranking explanation
  const showComparativeRanking = (ranking, position) => {
    if (!ranking || !ranking.ranks) return;

    // Explain the rank scale
    const rankLabel = position === 1 ? 'RANKED 1st' : 'RANKED 2nd';
    const explanation = position === 1
      ? 'Better on comparative evaluation'
      : 'Ranked lower on comparative evaluation';

    console.log(`   â­ ${rankLabel} (${explanation})`);

    // Show what made this candidate rank this way
    if (ranking.reason) {
      showText(`   ğŸ’¡ Why`, ranking.reason, 100);
    }

    // Show strengths/weaknesses
    if (ranking.strengths && ranking.strengths.length > 0) {
      console.log(`   âœ… Strengths: ${ranking.strengths.slice(0, 3).join(', ')}`);
      if (ranking.strengths.length > 3) {
        console.log(`      [+${ranking.strengths.length - 3} more strengths]`);
      }
    }

    if (ranking.weaknesses && ranking.weaknesses.length > 0) {
      console.log(`   âš ï¸  Weaknesses: ${ranking.weaknesses.slice(0, 3).join(', ')}`);
      if (ranking.weaknesses.length > 3) {
        console.log(`      [+${ranking.weaknesses.length - 3} more weaknesses]`);
      }
    }
  };

  const displayFinalist = (candidate, position) => {
    const globalId = `i${candidate.metadata.iteration}c${candidate.metadata.candidateId}`;
    const label = position === 1 ? 'ğŸ¥‡ WINNER' : 'ğŸ¥ˆ RUNNER-UP';
    const ranking = candidate.ranking || {};

    console.log(`\n${label} (${globalId}):`);

    // Show comparative ranking explanation (NEW)
    showComparativeRanking(ranking, position);

    // Show prompts (with expansion indicator)
    showText(`   ğŸ“ WHAT`, candidate.whatPrompt, 80);
    showText(`   ğŸ¨ HOW`, candidate.howPrompt, 80);

    // Show image reference
    if (candidate.image?.localPath) {
      const fs = require('fs');
      const exists = fs.existsSync(candidate.image.localPath);
      const status = exists ? 'âœ“ Found' : 'âœ— Missing';
      console.log(`   ğŸ–¼ï¸  Image: ${candidate.image.localPath} [${status}]`);
    } else {
      console.log(`   ğŸ–¼ï¸  Image: No image URL available`);
    }

    // Show combined prompt
    console.log(`   ğŸ”— Combined: "${candidate.combined.substring(0, 100)}${candidate.combined.length > 100 ? '...' : ''}"`);
  };

  // Show both candidates
  finalists.slice(0, 2).forEach((candidate, idx) => {
    displayFinalist(candidate, idx + 1);
  });

  // Show why winner won (the comparison that decided it)
  console.log('\n' + '-'.repeat(80));
  console.log('âš–ï¸  COMPARATIVE RANKING ANALYSIS:');
  console.log('-'.repeat(80));

  if (finalists.length >= 2) {
    const winnerRanking = winner.ranking || {};
    const runnerUp = finalists[1];
    const runnerRanking = runnerUp.ranking || {};

    // Show decisive reason from comparative ranking
    if (winnerRanking.reason) {
      console.log('\n   ğŸ’¡ Comparison Decision:');
      showText(`   `, winnerRanking.reason, 150);
    }

    // Show why winner was preferred
    console.log('\n   ğŸ† Winner advantages:');
    if (winnerRanking.strengths && winnerRanking.strengths.length > 0) {
      winnerRanking.strengths.forEach((strength, idx) => {
        console.log(`      ${idx + 1}. ${strength}`);
      });
    } else {
      console.log('      No specific strengths recorded');
    }

    // Show what runner-up lacked
    console.log('\n   ğŸ“‰ Runner-up weaknesses:');
    if (runnerRanking.weaknesses && runnerRanking.weaknesses.length > 0) {
      runnerRanking.weaknesses.forEach((weakness, idx) => {
        console.log(`      ${idx + 1}. ${weakness}`);
      });
    } else {
      console.log('      No specific weaknesses recorded');
    }

    // Show comparative dimensions if available
    if (winnerRanking.alignment !== undefined || winnerRanking.aesthetics !== undefined) {
      console.log('\n   ğŸ“Š Comparative evaluation:');
      console.log(`      Alignment: Winner preferred over runner-up`);
      console.log(`      Aesthetics: Winner preferred over runner-up`);
    }
  } else {
    console.log('   Only one finalist - no comparison available');
  }

  console.log('\n' + '='.repeat(80));
  console.log('ğŸ“‹ WINNER DETAILS');
  console.log('='.repeat(80));

  // Display scores (legacy fallback when not using ranking)
  if (winner.evaluation && winner.totalScore !== null) {
    console.log('\nğŸ“Š Scores (legacy mode):');
    console.log(`   â€¢ Total Score: ${winner.totalScore.toFixed(2)}/100`);
    console.log(`   â€¢ Alignment Score: ${winner.evaluation.alignmentScore}/100 (content match)`);
    console.log(`   â€¢ Aesthetic Score: ${winner.evaluation.aestheticScore}/10 (visual quality)`);
  }

  console.log('\nğŸ” Metadata:');
  const globalId = `i${winner.metadata.iteration}c${winner.metadata.candidateId}`;
  console.log(`   â€¢ Global ID: ${globalId} (iteration ${winner.metadata.iteration}, candidate ${winner.metadata.candidateId})`);
  if (winner.metadata.parentId !== undefined && winner.metadata.parentId !== null) {
    console.log(`   â€¢ Parent: i${winner.metadata.iteration - 1}c${winner.metadata.parentId}`);
  }
  console.log(`   â€¢ Last Refined Dimension: ${winner.metadata.dimension}`);

  console.log('\nğŸ“ Prompts:');
  console.log(`   â€¢ WHAT (content): "${winner.whatPrompt.substring(0, 80)}..."`);
  console.log(`   â€¢ HOW (style): "${winner.howPrompt.substring(0, 80)}..."`);
  console.log(`   â€¢ Combined: "${winner.combined.substring(0, 80)}..."`);

  console.log('\nğŸ–¼ï¸  Image:');
  // Check if URL is a data URL (base64 encoded) to avoid printing raw base64
  if (winner.image.url.startsWith('data:image/')) {
    console.log('   â€¢ URL: <base64 data URL - see local file>');
  } else {
    console.log(`   â€¢ URL: ${winner.image.url}`);
  }
  if (winner.image.localPath) {
    console.log(`   â€¢ Local: ${winner.image.localPath}`);
  }

  // Display evaluation info (available when using vision analysis)
  // or ranking details (when using comparative ranking)
  if (winner.evaluation) {
    console.log('\nğŸ“ˆ Evaluation:');
    console.log(`   â€¢ Analysis: ${winner.evaluation.analysis}`);
    if (winner.evaluation.strengths?.length > 0) {
      console.log(`   â€¢ Strengths: ${winner.evaluation.strengths.join(', ')}`);
    }
    if (winner.evaluation.weaknesses?.length > 0) {
      console.log(`   â€¢ Weaknesses: ${winner.evaluation.weaknesses.join(', ')}`);
    }
  } else if (winner.ranking) {
    // Show ranking details when no evaluation (comparative ranking mode)
    console.log('\nğŸ“ˆ Ranking Details:');
    if (winner.ranking.ranks) {
      const r = winner.ranking.ranks;
      console.log(`   â€¢ Alignment rank: ${r.alignment?.toFixed(2) || '?'} (1=best)`);
      console.log(`   â€¢ Aesthetics rank: ${r.aesthetics?.toFixed(2) || '?'} (1=best)`);
      console.log(`   â€¢ Combined score: ${r.combined?.toFixed(2) || '?'} (lower=better)`);
    }
    if (winner.ranking.winnerStrengths?.length > 0) {
      console.log(`   â€¢ Strengths: ${winner.ranking.winnerStrengths.join(', ')}`);
    }
    if (winner.ranking.loserWeaknesses?.length > 0) {
      console.log(`   â€¢ Competitors weak on: ${winner.ranking.loserWeaknesses.join(', ')}`);
    }
  }

  console.log('\nâ±ï¸  Performance:');
  console.log(`   â€¢ Total time: ${duration}s`);
  console.log(`   â€¢ Total candidates processed: ${candidateCount}`);
  console.log(`   â€¢ Iterations completed: ${iterationCount}`);

  console.log('\nğŸ“Š Session Metadata:');
  console.log(`   â€¢ Session ID: ${sessionId}`);
  console.log(`   â€¢ Metadata saved to: ${buildMetadataPath(DEFAULT_OUTPUT_DIR, sessionId)}`);
  console.log(`   â€¢ Images saved to: ${buildSessionPath(DEFAULT_OUTPUT_DIR, sessionId)}/`);

  // Display lineage info
  const metadata = await metadataTracker.getMetadata();
  if (metadata.lineage) {
    console.log('\nğŸŒ³ Winner Lineage (evolution path):');
    metadata.lineage.forEach((node, idx) => {
      const prefix = idx === 0 ? '   â”œâ”€' : '   â””â”€';
      console.log(`${prefix} Iteration ${node.iteration}, Candidate ${node.candidateId}`);
    });
  }

  // Display token efficiency report
  console.log('\n' + '='.repeat(80));
  console.log('ğŸ’° Token Efficiency Report');
  console.log('='.repeat(80));

  console.log(tokenTracker.formatSummary());

  // Display optimization suggestions
  console.log(tokenTracker.formatOptimizationReport());

  console.log('\n' + '='.repeat(80));
  console.log('âœ… Beam search completed successfully!');
  console.log('\nğŸ’¡ Key Observations:');
  console.log('   â€¢ Iteration 0: Generated 4 diverse candidates, kept top 2');
  console.log('   â€¢ Iteration 1: Refined WHAT (content), kept top 2');
  console.log('   â€¢ Iteration 2: Refined HOW (style), kept top 2');
  console.log('   â€¢ Unified pairwise ranking: Same algorithm for any N images');
  console.log(`   â€¢ Ensemble voting (${ensembleSize} votes/pair): Reduces ranking variance`);
  console.log('   â€¢ Transitive inference: Minimizes API calls (if A>B>C, skip A vs C)');
  console.log('   â€¢ Winner emerged through iterative refinement + selection pressure');
  console.log('   â€¢ Complete metadata and lineage tracked in metadata.json');
  console.log('   â€¢ Token efficiency tracking shows real costs and optimization opportunities');
  console.log('='.repeat(80));
  console.log();
}

// Run the demo
demo().catch(error => {
  console.error('\nâŒ Demo failed:', error);
  console.error('\nStack trace:');
  console.error(error.stack);
  process.exit(1);
});
