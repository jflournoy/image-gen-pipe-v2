/**
 * ðŸ”´ RED: GPU Coordination Integration Tests
 *
 * Tests for model coordinator GPU memory management across service switching
 * Ensures LLM, VLM, and Flux can switch on single 12GB GPU
 *
 * Gate: ENABLE_GPU_TESTS=1 to run (requires actual services and GPU)
 */

const { describe, test, beforeEach, afterEach } = require('node:test');
const assert = require('node:assert');
const nock = require('nock');
const axios = require('axios');

describe('GPU Coordination', () => {
  let modelCoordinator;
  const skipUnlessGPU = !process.env.ENABLE_GPU_TESTS;

  beforeEach(() => {
    // Clear module cache to get fresh instance
    delete require.cache[require.resolve('../../src/utils/model-coordinator.js')];
    modelCoordinator = require('../../src/utils/model-coordinator.js');
    nock.cleanAll();
  });

  afterEach(() => {
    nock.cleanAll();
  });

  describe('GPU Status Verification', () => {
    test('should verify GPU usage via health check (gpu_layers > 0)', async () => {
      nock('http://localhost:8003')
        .get('/health')
        .reply(200, {
          status: 'healthy',
          model_loaded: true,
          gpu_layers: 32,
          device: 'cuda'
        });

      const health = await axios.get('http://localhost:8003/health');

      assert.strictEqual(health.data.model_loaded, true, 'Model should be loaded');
      assert.ok(health.data.gpu_layers > 0, 'Should use GPU (gpu_layers > 0)');
      assert.strictEqual(health.data.device, 'cuda', 'Should use CUDA device');
    });

    test('should verify VLM GPU usage with all layers (-1)', async () => {
      nock('http://localhost:8004')
        .get('/health')
        .reply(200, {
          status: 'healthy',
          model_loaded: true,
          gpu_layers: -1,
          device: 'cuda'
        });

      const health = await axios.get('http://localhost:8004/health');

      assert.strictEqual(health.data.model_loaded, true, 'Model should be loaded');
      assert.strictEqual(health.data.gpu_layers, -1, 'Should indicate all layers on GPU');
      assert.ok(health.data.device === 'cuda', 'Should use CUDA device');
    });
  });

  describe('Integration Tests (Gated by ENABLE_GPU_TESTS)', () => {
    test('LLM health check confirms GPU usage', { skip: skipUnlessGPU }, async () => {
      // This test requires actual services running with GPU
      const health = await axios.get('http://localhost:8003/health', {
        timeout: 5000
      });

      assert.strictEqual(health.status, 200, 'Service should be healthy');
      assert.ok(health.data.model_loaded !== undefined, 'Should report model load status');

      if (health.data.model_loaded) {
        // If model is loaded, verify GPU usage
        assert.ok(health.data.gpu_layers !== 0, 'Should use GPU when model is loaded');
        assert.ok(
          health.data.device === 'cuda' || health.data.gpu_layers > 0,
          'Should indicate GPU usage'
        );
      }
    });

    test('VLM health check confirms GPU usage', { skip: skipUnlessGPU }, async () => {
      // This test requires actual services running with GPU
      const health = await axios.get('http://localhost:8004/health', {
        timeout: 5000
      });

      assert.strictEqual(health.status, 200, 'Service should be healthy');
      assert.ok(health.data.model_loaded !== undefined, 'Should report model load status');

      if (health.data.model_loaded) {
        // If model is loaded, verify GPU usage
        assert.ok(health.data.gpu_layers !== 0, 'Should use GPU when model is loaded');
        assert.ok(
          health.data.device === 'cuda' || health.data.gpu_layers < 0 || health.data.gpu_layers > 0,
          'Should indicate GPU usage'
        );
      }
    });

    test('Fluxâ†’VLM switching works without OOM', { skip: skipUnlessGPU }, async () => {
      // Check Flux health
      try {
        const fluxHealth = await axios.get('http://localhost:8001/health', {
          timeout: 5000
        });

        if (fluxHealth.data.model_loaded) {
          // If Flux is loaded, run VLM operation (unloads Flux, ensures VLM running)
          await modelCoordinator.withVLMOperation(async () => {});

          const vlmHealth = await axios.get('http://localhost:8004/health', {
            timeout: 5000
          });

          // VLM should be able to respond (may not be loaded yet, but service should be running)
          assert.ok(vlmHealth.status === 200, 'VLM service should respond after Flux unload');
        }
      } catch (error) {
        // Services may not be running - that's okay for this test
        console.log('Services not running for GPU test:', error.message);
      }
    });

    test('cleanupAll unloads all services safely', { skip: skipUnlessGPU }, async () => {
      // Cleanup all services
      await modelCoordinator.cleanupAll();

      // All services should be marked as unloaded
      const state = modelCoordinator.getModelStates();
      assert.ok(typeof state === 'object', 'Should have valid state after cleanup');
      assert.strictEqual(state.llm, false, 'LLM should be unloaded');
      assert.strictEqual(state.flux, false, 'Flux should be unloaded');
      assert.strictEqual(state.vision, false, 'Vision should be unloaded');
      assert.strictEqual(state.vlm, false, 'VLM should be unloaded');
    });
  });
});
