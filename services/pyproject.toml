[project]
name = "image-gen-services"
version = "1.0.0"
description = "Local Python services for image generation pipeline"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    # Core dependencies
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic>=2.4.0",

    # LLM service (llama.cpp)
    "llama-cpp-python>=0.2.0",

    # ML dependencies for Vision and Image services
    "torch>=2.1.0",
    "torchvision>=0.16.0",
    "transformers>=4.35.0",
    "diffusers>=0.24.0",
    "accelerate>=0.24.0",
    "huggingface_hub>=0.20.0",
    "protobuf>=4.25.0",
    "sentencepiece>=0.1.99",

    # Image processing
    "Pillow>=10.1.0",
    "requests>=2.31.0",
]

[project.optional-dependencies]
cuda = [
    # For CUDA-enabled llama-cpp-python, install separately:
    # uv pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
]
dev = [
    "pytest>=7.0.0",
]

[tool.uv]
# Use system torch if available to avoid re-downloading
# torch-index-url = "https://download.pytorch.org/whl/cu121"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
