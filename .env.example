# Provider Configuration
PROVIDER_MODE=mock  # Options: mock, real

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=  # Optional: Your OpenAI organization ID

# Model Configuration (Updated December 2025 - Cost-Optimized Defaults)
# See src/config/model-pricing.js for complete pricing information
#
# Cost comparison (per 1M input tokens):
# - gpt-5-nano: $0.05 (best for simple tasks: expand, combine)
# - gpt-5-mini: $0.25 (recommended for most tasks: refine, critique)
# - gpt-5.1: $1.25 (flagship reasoning model)
# - gpt-4o-mini: $0.15 (recommended for vision tasks)
# - gpt-4o: $2.50 (premium vision)
# - gpt-4: $30.00 (legacy, avoid if possible)
#
# LLM Model Configuration (Two approaches available):
#
# Approach 1: Single model for all LLM operations (simple)
OPENAI_LLM_MODEL=gpt-5-mini  # Used for all operations if specific models not set
#
# Approach 2: Operation-specific models for maximum cost optimization (RECOMMENDED)
# These override OPENAI_LLM_MODEL for specific operations
OPENAI_LLM_MODEL_EXPAND=gpt-5-nano   # Simple expansion: $0.05/1M (3x cheaper than 4o-mini!)
OPENAI_LLM_MODEL_REFINE=gpt-5-mini   # Complex refinement: $0.25/1M (best quality/cost)
OPENAI_LLM_MODEL_COMBINE=gpt-5-nano  # Simple combining: $0.05/1M (3x cheaper!)
#
# Cost savings with operation-specific GPT-5 models:
# - Per 10K token run: $0.0015 (vs $0.30 with GPT-4)
# - Annual (1000 runs): $1.50 (vs $300 with GPT-4) - 99.5% savings!
# - Using nano for expand/combine provides additional 5x savings on those operations

OPENAI_IMAGE_MODEL=gpt-image-1-mini  # GPT Image 1 Mini (cost-efficient, $0.011 per 1024x1024 medium image)
OPENAI_VISION_MODEL=gpt-4o-mini  # Best value for vision: $0.15/1M tokens

# API Behavior
OPENAI_MAX_RETRIES=3
OPENAI_TIMEOUT_MS=30000
