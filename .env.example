# Provider Configuration
PROVIDER_MODE=mock  # Options: mock, real

# Default Provider Selection
# These determine which providers are used when the server starts
# Set to local providers to avoid needing OpenAI API key
LLM_PROVIDER=openai      # Options: openai, local-llm
IMAGE_PROVIDER=dalle     # Options: dalle, flux, bfl, modal
VISION_PROVIDER=gpt-vision  # Options: gpt-vision, local

# For fully local setup (no API keys needed), use:
# LLM_PROVIDER=local-llm
# IMAGE_PROVIDER=flux
# VISION_PROVIDER=local

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=  # Optional: Your OpenAI organization ID

# Model Configuration (Updated December 2025 - Cost-Optimized Defaults)
# See src/config/model-pricing.js for complete pricing information
#
# Cost comparison (per 1M input tokens):
# - gpt-5-nano: $0.05 (best for simple tasks: expand, combine)
# - gpt-5-mini: $0.25 (recommended for most tasks: refine, critique)
# - gpt-5.1: $1.25 (flagship reasoning model)
# - gpt-4o-mini: $0.15 (recommended for vision tasks)
# - gpt-4o: $2.50 (premium vision)
# - gpt-4: $30.00 (legacy, avoid if possible)
#
# LLM Model Configuration (Two approaches available):
#
# Approach 1: Single model for all LLM operations (simple)
OPENAI_LLM_MODEL=gpt-5-mini  # Used for all operations if specific models not set
#
# Approach 2: Operation-specific models for maximum cost optimization (RECOMMENDED)
# These override OPENAI_LLM_MODEL for specific operations
OPENAI_LLM_MODEL_EXPAND=gpt-5-nano   # Simple expansion: $0.05/1M (3x cheaper than 4o-mini!)
OPENAI_LLM_MODEL_REFINE=gpt-5-mini   # Complex refinement: $0.25/1M (best quality/cost)
OPENAI_LLM_MODEL_COMBINE=gpt-5-nano  # Simple combining: $0.05/1M (3x cheaper!)
#
# Cost savings with operation-specific GPT-5 models:
# - Per 10K token run: $0.0015 (vs $0.30 with GPT-4)
# - Annual (1000 runs): $1.50 (vs $300 with GPT-4) - 99.5% savings!
# - Using nano for expand/combine provides additional 5x savings on those operations

OPENAI_IMAGE_MODEL=gpt-image-1-mini  # GPT Image 1 Mini (cost-efficient, $0.011 per 1024x1024 medium image)
OPENAI_VISION_MODEL=gpt-4o-mini  # Best value for vision: $0.15/1M tokens

# API Behavior
OPENAI_MAX_RETRIES=3
OPENAI_TIMEOUT_MS=30000

# Flux LoRA Configuration (Optional)
# Leave empty to use Flux without LoRA
FLUX_LORA_PATH=  # Path to LoRA weights (e.g., services/loras/flux-custom-lora.safetensors)
FLUX_LORA_SCALE=0.8  # LoRA strength (0.0-2.0, typically 0.7-1.0)

# Local Vision-Language Model (VLM) for Image Comparison
# Used for pairwise image ranking in beam search
# Recommended: Qwen2.5-VL-7B-Instruct (pure vision-language)
# Alternatives: LLaVA 1.6, LLaVA 1.5 (see services/README.md for details)
VLM_MODEL_REPO=unsloth/Qwen2.5-VL-7B-Instruct-GGUF
VLM_MODEL_FILE=*Q4_K_M.gguf
VLM_CLIP_FILE=*mmproj-F16.gguf
VLM_GPU_LAYERS=-1  # -1 = all layers on GPU, 0 = CPU only
VLM_CONTEXT_SIZE=4096

# Black Forest Labs (BFL) API Configuration
# Cloud-based image generation using Flux models
# Get API key at: https://bfl.ml
BFL_API_KEY=  # Your BFL API key (required to use BFL provider)
BFL_API_URL=https://api.bfl.ai  # BFL API base URL
BFL_MODEL=flux-pro-1.1  # Available: flux-pro-1.1, flux-pro, flux-dev, flux-2-pro, flux-2-flex, etc.
BFL_WIDTH=1024  # Image width (256-2048, multiples of 16)
BFL_HEIGHT=1024  # Image height (256-2048, multiples of 16)
BFL_MAX_POLL_TIME=300000  # Max polling time for async generation (ms, default 5 min)
BFL_POLL_INTERVAL=2000  # Poll interval between checks (ms, default 2 sec)

# Modal (Cloud GPU) API Configuration
# Serverless GPU inference using Modal.com
# Deploy with: modal deploy services/modal_diffusion_service.py
# Get credentials at: https://modal.com/settings
MODAL_ENDPOINT_URL=  # Your Modal web endpoint URL (e.g., https://your-app--generate.modal.run)
MODAL_TOKEN_ID=  # Modal authentication token ID
MODAL_TOKEN_SECRET=  # Modal authentication token secret
MODAL_MODEL=flux-dev  # Default model: flux-dev, flux-schnell, sdxl-turbo, sdxl-base, sd3-medium
MODAL_GPU=A10G  # GPU type: T4, A10G, A100-40GB, A100-80GB, H100
MODAL_WIDTH=1024  # Image width (64-2048)
MODAL_HEIGHT=1024  # Image height (64-2048)
MODAL_STEPS=25  # Inference steps (1-100)
MODAL_GUIDANCE=3.5  # Guidance scale (0.0-20.0)
MODAL_TIMEOUT=300000  # Request timeout in ms (default 5 min for cold starts)

# CivitAI API Configuration
# Used for downloading custom models via modal_model_manager.py
# Get API key at: https://civitai.com/user/account
CIVIT_API_KEY=  # Your CivitAI API key (required for downloading models)
